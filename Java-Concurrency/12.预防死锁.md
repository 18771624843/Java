#12.预防死锁

在某些情况，死锁是可以预防的。下面介绍三种可以预防死锁的技术：

* 加锁顺序
* 加锁超时
* 死锁检测


##加锁顺序（Lock Ordering）

当多个线程需要相同的锁，但以不同的顺序获取锁时，这时死锁就很容易发生。

如果所有的锁都是按照相同的顺序获取，那么死锁是不会出现的。看下下面的例子：

```
Thread 1:

  lock A 
  lock B
---------------------
Thread 2:

   wait for A
   lock C (when A locked)
---------------------
Thread 3:

   wait for A
   wait for B
   wait for C
```

如果一个线程，例如线程3，需要一些锁，那么她必须按照一定的顺序获取锁。只有按照顺序获取前面的锁，才能够依次获取后面的锁。

例如，线程2和线程3，只有当它们获得锁A后才能够去尝试获取锁C。由于线程1持有锁A，线程2和线程3都会阻塞直至锁A被线程1释放。

顺序加锁是一个非常有效的用于预防死锁的机制。然而，它只有预先知道所有的加锁顺序时才能很好的地工作，它并不适用于所有情况。（However, it can only be used if you know about all locks needed ahead of taking any of the locks. This is not always the case.）


##加锁超时（Lock Timeout）

另一种预防死锁的机制就是试图获取锁时设置超时。如果线程在规定时间内没有获得锁，则会放弃，并释放自身锁持有的锁，等待一个随机时间，然后重试。在随机等待时间内，给予其他线程获取相同的锁，从而避免死锁发生。

下面是两个线程尝试以不同的顺序获取两个锁，在超时回退后进行重试的例子：

```
Thread 1 locks A
Thread 2 locks B

Thread 1 attempts to lock B but is blocked
Thread 2 attempts to lock A but is blocked

Thread 1's lock attempt on B times out
Thread 1 backs up and releases A as well
Thread 1 waits randomly (e.g. 257 millis) before retrying.

Thread 2's lock attempt on A times out
Thread 2 backs up and releases B as well
Thread 2 waits randomly (e.g. 43 millis) before retrying.
```

在上面的例子中，线程2比线程1早大约200ms进行重新加锁，因此很有可能可以取到全部的锁。线程1尝试获取锁A，由于2持有所有A，所以线程1进入等待状态。当线程2执行完释放所有的锁，线程1就可以持有所有的锁了。（除非有其他线程也在争夺锁A和锁B）

有个问题需要注意的就是，如果出现了加锁超时，并不意味着出现了死锁。加锁超时可能是因为某个持有锁的线程需要大量的时间来执行任务。

另外，如果有大量的线程去争夺相同的资源，即使有加锁超时和重试机制，也有可能会导致线程不停地重试但却无法获取所需的锁。如果只有两个线程，且重试时间在0-500ms之间，也许死锁不会发生。但如果线程在10-20之间情况则有可能不同，因为这些线程中的超时重试时间很大概率生是相同或相近的。

加锁超时机制的一个缺点是：Java并不提供进入synchronized块的超时设置。你可以自定义锁或使用Java 5提供的在`java.util.concurrency`包中的工具类。自定义锁并不困难，但是超出了本文的内容。后面的教程会做详细讲解。

##死锁检测（Deadlock Detection）

Deadlock detection is a heavier deadlock prevention mechanism aimed at cases in which lock ordering isn't possible, and lock timeout isn't feasible.

Every time a thread takes a lock it is noted in a data structure (map, graph etc.) of threads and locks. Additionally, whenever a thread requests a lock this is also noted in this data structure.

When a thread requests a lock but the request is denied, the thread can traverse the lock graph to check for deadlocks. For instance, if a Thread A requests lock 7, but lock 7 is held by Thread B, then Thread A can check if Thread B has requested any of the locks Thread A holds (if any). If Thread B has requested so, a deadlock has occurred (Thread A having taken lock 1, requesting lock 7, Thread B having taken lock 7, requesting lock 1).

Of course a deadlock scenario may be a lot more complicated than two threads holding each others locks. Thread A may wait for Thread B, Thread B waits for Thread C, Thread C waits for Thread D, and Thread D waits for Thread A. In order for Thread A to detect a deadlock it must transitively examine all requested locks by Thread B. From Thread B's requested locks Thread A will get to Thread C, and then to Thread D, from which it finds one of the locks Thread A itself is holding. Then it knows a deadlock has occurred.

Below is a graph of locks taken and requested by 4 threads (A, B, C and D). A data structure like this that can be used to detect deadlocks.

Deadlock Detection Data Structure

![enter image description here](http://tutorials.jenkov.com/images/java-concurrency/deadlock-detection-graph.png)

So what do the threads do if a deadlock is detected?

One possible action is to release all locks, backup, wait a random amount of time and then retry. This is similar to the simpler lock timeout mechanism except threads only backup when a deadlock has actually occurred. Not just because their lock requests timed out. However, if a lot of threads are competing for the same locks they may repeatedly end up in a deadlock even if they back up and wait.

A better option is to determine or assign a priority of the threads so that only one (or a few) thread backs up. The rest of the threads continue taking the locks they need as if no deadlock had occurred. If the priority assigned to the threads is fixed, the same threads will always be given higher priority. To avoid this you may assign the priority randomly whenever a deadlock is detected.
